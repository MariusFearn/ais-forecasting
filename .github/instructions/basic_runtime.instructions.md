# AIS Vessel Trajectory Prediction - Quick Reference




```

## ğŸ“ Project sturckture - we do not change this strukture - keep attention if you create new files to put them in the right place
ais-forecasting/
â”œâ”€â”€ .github/                    # Contains GitHub-specific files, like CI/CD workflows.
â”‚
â”œâ”€â”€ config/                     # Stores all project configuration files.
â”‚   â”œâ”€â”€ default.yaml            # Default parameters for the entire project.
â”‚   â””â”€â”€ experiment_configs/     # Configurations for specific machine learning experiments.
â”‚       â”œâ”€â”€ nbeats_experiment.yaml # Settings for an N-BEATS model experiment.
â”‚       â””â”€â”€ tft_experiment.yaml    # Settings for a Temporal Fusion Transformer experiment.
â”‚
â”œâ”€â”€ data/                       # Holds all data used in the project.
â”‚   â”œâ”€â”€ raw/                    # Raw, immutable data. Should not be modified.
â”‚   â”œâ”€â”€ processed/              # Cleaned, transformed, and feature-engineered data.
â”‚   â”‚   â”œâ”€â”€ training_sets/      # Final datasets ready for model training.
â”‚   â”‚   â”œâ”€â”€ vessel_features/    # Intermediate features extracted for each vessel.
â”‚   â”‚   â””â”€â”€ predictions/        # Stores the output predictions from models.
â”‚   â””â”€â”€ models/                 # Contains all trained model artifacts.
â”‚       â”œâ”€â”€ final_models/       # Serialized, production-ready models.
â”‚       â”œâ”€â”€ checkpoints/        # Saved states during large model training.
â”‚       â””â”€â”€ hyperparameter_logs/# Logs from hyperparameter optimization runs.
â”‚
â”œâ”€â”€ experiments/                # Tracks results and artifacts from ML experiments.
â”‚   â”œâ”€â”€ baseline_experiments/   # Results from simple baseline models.
â”‚   â”œâ”€â”€ nbeats_experiments/     # Results from N-BEATS model experiments.
â”‚   â””â”€â”€ tft_experiments/        # Results from TFT model experiments.
â”‚
â”œâ”€â”€ notebooks/                  # Jupyter notebooks for interactive analysis and visualization.
â”‚   â”œâ”€â”€ exploratory.ipynb       # Initial data exploration and analysis.
â”‚   â”œâ”€â”€ preprocessing.ipynb     # Interactive data cleaning and preparation.
â”‚   â”œâ”€â”€ model_development.ipynb # Prototyping and developing new models.
â”‚   â”œâ”€â”€ evaluation.ipynb        # In-depth evaluation of model performance.
â”‚   â””â”€â”€ visual_training_analysis.ipynb # Visualizing the full training pipeline.
â”‚
â”œâ”€â”€ scripts/                    # Contains standalone, executable scripts for core tasks. (should not containe functions, use src for functions)
â”‚   â”œâ”€â”€ create_simple_training_data.py # Generates a small, single-vessel dataset.
â”‚   â”œâ”€â”€ train_simple_model.py   # Trains a baseline model on the simple dataset.
â”‚   â”œâ”€â”€ create_multi_vessel_training_data.py # Generates the full training dataset.
â”‚   â”œâ”€â”€ train_enhanced_model.py # Trains the primary, enhanced model.
â”‚   â”œâ”€â”€ evaluate.py             # Runs model evaluation from the command line.
â”‚   â”œâ”€â”€ predict.py              # Runs predictions using a trained model.
â”‚   â”œâ”€â”€ test_simple.py          # A simple test script for quick validation.
â”‚   â”œâ”€â”€ create_training_data.py # Delete: Redundant, functionality is split.
â”‚   â”œâ”€â”€ train.py                # Delete: Redundant, functionality is split.
â”‚   â””â”€â”€ quick_start_h3.py       # Delete: Old script, functionality now in notebooks.
â”‚
â”œâ”€â”€ src/                        # Contains all the project's source code as a Python package.
â”‚   â”œâ”€â”€ __init__.py             # Makes 'src' a package, allowing imports.
â”‚   â”œâ”€â”€ data/                   # Modules for data loading and preprocessing.
â”‚   â”œâ”€â”€ features/               # Modules for feature engineering and transformation.
â”‚   â”œâ”€â”€ models/                 # Python definitions of model architectures.
â”‚   â”œâ”€â”€ utils/                  # Reusable utility functions and helper classes.
â”‚   â””â”€â”€ visualization/          # Code for generating plots and maps.
â”‚
â”œâ”€â”€ tests/                      # Contains all tests for the project source code.
â”‚   â”œâ”€â”€ test_data.py            # Unit tests for data loading and validation.
â”‚   â”œâ”€â”€ test_features.py        # Unit tests for the feature engineering pipeline.
â”‚   â””â”€â”€ test_models.py          # Unit tests for model input/output validation.
â”‚
â”œâ”€â”€ visualizations/             # Stores saved output plots, maps, and other visuals.
â”‚   â”œâ”€â”€ *.html                  # Interactive maps and plots generated by notebooks/scripts.
â”‚   â””â”€â”€ ultra_fast_maritime_visualization.py # Move: This is a script, not a visualization.
â”‚
â”œâ”€â”€ README.md                   # This file: The main documentation for the project.
â”œâ”€â”€ requirements.txt            # A list of all Python packages required to run the project. Update this if we need new models and make sure we are in ML environment if we install something.
â””â”€â”€ .gitignore                  # Specifies files and folders to be ignored by Git.

## ğŸ¯ Next Steps
1. Scale up training data (more vessels)
2. Try XGBoost model
3. Add visualization tools

In terminal we use conda ML - not base - conda activate ML must be run before running any scripts or notebooks.
