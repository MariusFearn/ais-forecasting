# Massive H3 Prediction Experiment Configuration
# Phase 5: Large-scale training with all available data and features

defaults:
  - ../default

experiment:
  name: "massive_h3_prediction"
  description: "Phase 5: Large-scale training with maximum data and features"
  phase: 5

# Data configuration
data:
  training_data_path: "data/processed/training_sets/massive_h3_sequences.pkl"
  target: "target_h3_cell"
  exclude_columns:
    - "target_h3_cell"
    - "vessel_imo"
    - "data_year"
  test_size: 0.15  # Smaller test set for massive data
  random_state: 42

# Model configuration
model:
  type: "xgboost"
  parameters:
    n_estimators: 200
    max_depth: 10
    learning_rate: 0.1
    subsample: 0.8
    colsample_bytree: 0.8
    random_state: 42
    n_jobs: -1

# Training configuration
training:
  use_feature_selection: true
  top_k_features: 25
  apply_phase5_fixes: true
  handle_single_sample_classes: true
  memory_efficient: true

# Feature selection configuration
feature_selection:
  method: "mutual_info_classif"
  
# Output configuration
output:
  model_path: "data/models/final_models/massive_h3_predictor.pkl"
  encoder_path: "data/models/final_models/massive_h3_encoder.pkl"
  metadata_path: "data/models/final_models/massive_model_metadata.pkl"

# Evaluation configuration
evaluation:
  include_feature_importance: true
  include_distance_evaluation: true
  distance_sample_size: 1000  # Larger sample for massive data
  sample_prediction_test: true

# Performance configuration
performance:
  chunked_loading: true
  chunk_size: 10000
  memory_monitoring: true
