{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4d955c76",
   "metadata": {},
   "source": [
    "# AIS Vessel Trajectory Prediction - Visual Analysis\n",
    "\n",
    "This notebook provides a complete visual walkthrough of our vessel H3 cell prediction system:\n",
    "\n",
    "1. **Raw Vessel Data Exploration** - See what data we have\n",
    "2. **H3 Grid Visualization** - Understand the spatial framework \n",
    "3. **Feature Engineering** - Transform raw data into ML features\n",
    "4. **Model Training & Results** - Train and evaluate our predictor\n",
    "5. **Prediction Visualization** - See model predictions on maps\n",
    "\n",
    "Let's start exploring! üö¢üó∫Ô∏è"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffc6472c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import all required libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import folium\n",
    "import h3\n",
    "import sys\n",
    "import os\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Add our source code to path\n",
    "sys.path.append('../src')\n",
    "\n",
    "from features.vessel_h3_tracker import VesselH3Tracker\n",
    "from features.vessel_features import VesselFeatureExtractor\n",
    "\n",
    "# Set up plotting\n",
    "plt.style.use('default')\n",
    "sns.set_palette(\"husl\")\n",
    "%matplotlib inline\n",
    "\n",
    "print(\"üì¶ All libraries imported successfully!\")\n",
    "print(\"üöÄ Ready to explore vessel trajectory prediction!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b70f424c",
   "metadata": {},
   "source": [
    "## 1. Raw Vessel Data Exploration üõ≥Ô∏è\n",
    "\n",
    "Let's start by loading and exploring our raw AIS vessel data to understand what we're working with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84d47b30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load raw vessel data\n",
    "print(\"üìä Loading raw vessel data...\")\n",
    "df = pd.read_pickle('../data/raw/ais_cape_data_2024.pkl')\n",
    "\n",
    "print(f\"‚úÖ Loaded {len(df):,} AIS records\")\n",
    "print(f\"üìÖ Date range: {df['mdt'].min()} to {df['mdt'].max()}\")\n",
    "print(f\"üö¢ Unique vessels: {df['imo'].nunique()}\")\n",
    "print(f\"üìç Geographic bounds:\")\n",
    "print(f\"   Latitude: {df['lat'].min():.3f} to {df['lat'].max():.3f}\")\n",
    "print(f\"   Longitude: {df['lon'].min():.3f} to {df['lon'].max():.3f}\")\n",
    "\n",
    "# Show sample data\n",
    "print(\"\\nüìã Sample data:\")\n",
    "display(df[['imo', 'mdt', 'lat', 'lon', 'speed', 'heading', 'destination']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caf7250e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze vessel activity\n",
    "vessel_counts = df['imo'].value_counts()\n",
    "\n",
    "# Plot vessel activity distribution\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "\n",
    "# 1. Records per vessel\n",
    "axes[0,0].hist(vessel_counts.values, bins=50, alpha=0.7, color='skyblue')\n",
    "axes[0,0].set_title('Distribution of Records per Vessel')\n",
    "axes[0,0].set_xlabel('Number of AIS Records')\n",
    "axes[0,0].set_ylabel('Number of Vessels')\n",
    "axes[0,0].axvline(vessel_counts.median(), color='red', linestyle='--', label=f'Median: {vessel_counts.median():.0f}')\n",
    "axes[0,0].legend()\n",
    "\n",
    "# 2. Speed distribution\n",
    "axes[0,1].hist(df['speed'].dropna(), bins=50, alpha=0.7, color='lightgreen')\n",
    "axes[0,1].set_title('Vessel Speed Distribution')\n",
    "axes[0,1].set_xlabel('Speed (knots)')\n",
    "axes[0,1].set_ylabel('Frequency')\n",
    "axes[0,1].axvline(df['speed'].median(), color='red', linestyle='--', label=f'Median: {df[\"speed\"].median():.1f} knots')\n",
    "axes[0,1].legend()\n",
    "\n",
    "# 3. Geographic distribution\n",
    "axes[1,0].scatter(df['lon'], df['lat'], alpha=0.1, s=0.5, color='navy')\n",
    "axes[1,0].set_title('Geographic Distribution of AIS Points')\n",
    "axes[1,0].set_xlabel('Longitude')\n",
    "axes[1,0].set_ylabel('Latitude')\n",
    "axes[1,0].grid(True, alpha=0.3)\n",
    "\n",
    "# 4. Temporal distribution\n",
    "df['hour'] = df['mdt'].dt.hour\n",
    "hourly_counts = df['hour'].value_counts().sort_index()\n",
    "axes[1,1].bar(hourly_counts.index, hourly_counts.values, alpha=0.7, color='orange')\n",
    "axes[1,1].set_title('AIS Messages by Hour of Day')\n",
    "axes[1,1].set_xlabel('Hour of Day')\n",
    "axes[1,1].set_ylabel('Number of Messages')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"üìä Top 5 most active vessels:\")\n",
    "for i, (imo, count) in enumerate(vessel_counts.head().items()):\n",
    "    print(f\"   {i+1}. Vessel {imo}: {count:,} records\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29d8f9d8",
   "metadata": {},
   "source": [
    "## 2. H3 Grid Visualization üó∫Ô∏è\n",
    "\n",
    "Now let's visualize our H3 hexagonal grid system and see how it overlays with the vessel data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbde0dad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select our test vessel (most active one)\n",
    "test_vessel_imo = vessel_counts.index[0]\n",
    "test_vessel_data = df[df['imo'] == test_vessel_imo].head(200).copy()  # First 200 points for visualization\n",
    "\n",
    "print(f\"üö¢ Selected vessel {test_vessel_imo} for detailed analysis\")\n",
    "print(f\"üìä Using {len(test_vessel_data)} data points\")\n",
    "print(f\"üìÖ Time span: {test_vessel_data['mdt'].min()} to {test_vessel_data['mdt'].max()}\")\n",
    "\n",
    "# Convert to H3 cells\n",
    "tracker = VesselH3Tracker(h3_resolution=5)\n",
    "h3_sequence = tracker.convert_vessel_to_h3_sequence(test_vessel_data)\n",
    "\n",
    "print(f\"‚úÖ Converted to {len(h3_sequence)} H3 positions\")\n",
    "print(f\"üó∫Ô∏è H3 resolution 5: ~{h3.edge_length(5, unit='km'):.1f}km cell edge length\")\n",
    "\n",
    "# Get unique H3 cells visited\n",
    "unique_cells = h3_sequence['h3_cell'].unique()\n",
    "print(f\"üìç Vessel visited {len(unique_cells)} unique H3 cells\")\n",
    "\n",
    "display(h3_sequence[['mdt', 'lat', 'lon', 'h3_cell', 'speed', 'heading']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "856eab66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an interactive map with H3 grid overlay\n",
    "def create_h3_vessel_map(vessel_data, h3_sequence):\n",
    "    \"\"\"Create an interactive map showing vessel track with H3 grid\"\"\"\n",
    "    \n",
    "    # Calculate map center\n",
    "    center_lat = vessel_data['lat'].mean()\n",
    "    center_lon = vessel_data['lon'].mean()\n",
    "    \n",
    "    # Create base map\n",
    "    m = folium.Map(\n",
    "        location=[center_lat, center_lon],\n",
    "        zoom_start=10,\n",
    "        tiles='OpenStreetMap'\n",
    "    )\n",
    "    \n",
    "    # Add vessel track as a line\n",
    "    track_coords = [[row['lat'], row['lon']] for _, row in vessel_data.iterrows()]\n",
    "    folium.PolyLine(\n",
    "        track_coords,\n",
    "        color='blue',\n",
    "        weight=3,\n",
    "        opacity=0.8,\n",
    "        popup='Vessel Track'\n",
    "    ).add_to(m)\n",
    "    \n",
    "    # Add H3 cells as hexagons\n",
    "    unique_cells = h3_sequence['h3_cell'].unique()\n",
    "    \n",
    "    for i, cell_id in enumerate(unique_cells[:50]):  # Limit to first 50 for performance\n",
    "        # Get hexagon boundary\n",
    "        boundary = h3.h3_to_geo_boundary(cell_id, geo_json=True)\n",
    "        \n",
    "        # Color based on visit order\n",
    "        color = plt.cm.viridis(i / min(len(unique_cells), 50))\n",
    "        hex_color = f\"#{int(color[0]*255):02x}{int(color[1]*255):02x}{int(color[2]*255):02x}\"\n",
    "        \n",
    "        folium.Polygon(\n",
    "            boundary,\n",
    "            color=hex_color,\n",
    "            weight=2,\n",
    "            fillColor=hex_color,\n",
    "            fillOpacity=0.3,\n",
    "            popup=f'H3 Cell: {cell_id}'\n",
    "        ).add_to(m)\n",
    "    \n",
    "    # Add start and end markers\n",
    "    start_point = vessel_data.iloc[0]\n",
    "    end_point = vessel_data.iloc[-1]\n",
    "    \n",
    "    folium.Marker(\n",
    "        [start_point['lat'], start_point['lon']],\n",
    "        popup='Start',\n",
    "        icon=folium.Icon(color='green', icon='play')\n",
    "    ).add_to(m)\n",
    "    \n",
    "    folium.Marker(\n",
    "        [end_point['lat'], end_point['lon']],\n",
    "        popup='End',\n",
    "        icon=folium.Icon(color='red', icon='stop')\n",
    "    ).add_to(m)\n",
    "    \n",
    "    return m\n",
    "\n",
    "# Create the map\n",
    "print(\"üó∫Ô∏è Creating interactive H3 grid map...\")\n",
    "vessel_map = create_h3_vessel_map(test_vessel_data, h3_sequence)\n",
    "\n",
    "# Save and display\n",
    "map_path = '../visualizations/vessel_h3_training_data.html'\n",
    "vessel_map.save(map_path)\n",
    "print(f\"üíæ Map saved to: {map_path}\")\n",
    "\n",
    "# Display in notebook\n",
    "vessel_map"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "040bd8fe",
   "metadata": {},
   "source": [
    "## 3. Feature Engineering Transformation üîß\n",
    "\n",
    "Now let's see how we transform the raw vessel positions into the 65 features used for machine learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ac093ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract features using our feature engineering pipeline\n",
    "print(\"üîß Extracting vessel features...\")\n",
    "extractor = VesselFeatureExtractor(h3_resolution=5)\n",
    "features_df = extractor.extract_all_features(h3_sequence)\n",
    "\n",
    "print(f\"‚úÖ Extracted {len(features_df.columns)} features for {len(features_df)} time points\")\n",
    "print(f\"üìä Feature categories include:\")\n",
    "print(\"   - Core state (position, speed, heading)\")\n",
    "print(\"   - Historical patterns (6h, 12h, 24h windows)\")\n",
    "print(\"   - Movement characteristics (efficiency, trends)\")\n",
    "print(\"   - Contextual information (journey phase, cargo status)\")\n",
    "\n",
    "# Show sample features\n",
    "key_features = ['current_h3_cell', 'current_speed', 'current_heading', 'time_in_current_cell', \n",
    "                'avg_speed_6h', 'speed_trend_6h', 'journey_phase', 'likely_cargo_status']\n",
    "\n",
    "print(\"\\nüìã Sample engineered features:\")\n",
    "display(features_df[key_features].head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b04f451",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize feature distributions and patterns\n",
    "fig, axes = plt.subplots(2, 3, figsize=(18, 10))\n",
    "\n",
    "# 1. Speed over time\n",
    "axes[0,0].plot(features_df.index, features_df['current_speed'], alpha=0.7, label='Current Speed')\n",
    "axes[0,0].plot(features_df.index, features_df['avg_speed_6h'], alpha=0.7, label='6h Average')\n",
    "axes[0,0].set_title('Speed Patterns')\n",
    "axes[0,0].set_xlabel('Time Index')\n",
    "axes[0,0].set_ylabel('Speed (knots)')\n",
    "axes[0,0].legend()\n",
    "axes[0,0].grid(True, alpha=0.3)\n",
    "\n",
    "# 2. Time in cell distribution\n",
    "axes[0,1].hist(features_df['time_in_current_cell'].dropna(), bins=20, alpha=0.7, color='lightblue')\n",
    "axes[0,1].set_title('Time Spent in H3 Cells')\n",
    "axes[0,1].set_xlabel('Time in Cell')\n",
    "axes[0,1].set_ylabel('Frequency')\n",
    "\n",
    "# 3. Movement efficiency\n",
    "axes[0,2].hist(features_df['movement_efficiency_6h'].dropna(), bins=20, alpha=0.7, color='lightgreen')\n",
    "axes[0,2].set_title('Movement Efficiency (6h)')\n",
    "axes[0,2].set_xlabel('Efficiency Ratio')\n",
    "axes[0,2].set_ylabel('Frequency')\n",
    "\n",
    "# 4. Cells visited over time\n",
    "axes[1,0].plot(features_df.index, features_df['cells_visited_6h'], alpha=0.7, color='orange')\n",
    "axes[1,0].set_title('H3 Cells Visited (6h window)')\n",
    "axes[1,0].set_xlabel('Time Index')\n",
    "axes[1,0].set_ylabel('Number of Cells')\n",
    "axes[1,0].grid(True, alpha=0.3)\n",
    "\n",
    "# 5. Journey phase distribution\n",
    "phase_counts = features_df['journey_phase'].value_counts()\n",
    "axes[1,1].pie(phase_counts.values, labels=phase_counts.index, autopct='%1.1f%%')\n",
    "axes[1,1].set_title('Journey Phase Distribution')\n",
    "\n",
    "# 6. Speed trend patterns\n",
    "trend_counts = features_df['speed_trend_6h'].value_counts()\n",
    "axes[1,2].bar(trend_counts.index, trend_counts.values, alpha=0.7, color='purple')\n",
    "axes[1,2].set_title('Speed Trend Patterns (6h)')\n",
    "axes[1,2].set_xlabel('Trend')\n",
    "axes[1,2].set_ylabel('Frequency')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"üìä Feature engineering summary:\")\n",
    "print(f\"   - Non-null features: {features_df.count().sum()} / {len(features_df) * len(features_df.columns)}\")\n",
    "print(f\"   - Completeness: {(features_df.count().sum() / (len(features_df) * len(features_df.columns)) * 100):.1f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf0a373d",
   "metadata": {},
   "source": [
    "## 4. Training Data Creation üìä\n",
    "\n",
    "Let's create the training sequences and see what our model will learn from."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94bbf52b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create training sequences (input ‚Üí target pairs)\n",
    "print(\"üìä Creating training sequences...\")\n",
    "\n",
    "sequences = []\n",
    "for i in range(len(features_df) - 1):  # -1 because we need next cell\n",
    "    current_row = features_df.iloc[i]\n",
    "    next_row = features_df.iloc[i + 1]\n",
    "    \n",
    "    # Simple input features\n",
    "    input_features = {\n",
    "        'current_h3_cell': current_row['current_h3_cell'],\n",
    "        'current_speed': current_row['current_speed'],\n",
    "        'current_heading': current_row['current_heading'],\n",
    "        'lat': current_row['lat'],\n",
    "        'lon': current_row['lon'],\n",
    "        'time_in_current_cell': current_row['time_in_current_cell']\n",
    "    }\n",
    "    \n",
    "    # Target: next H3 cell\n",
    "    target = next_row['current_h3_cell']\n",
    "    \n",
    "    # Combine\n",
    "    sequence = {**input_features, 'target_h3_cell': target}\n",
    "    sequences.append(sequence)\n",
    "\n",
    "training_df = pd.DataFrame(sequences)\n",
    "\n",
    "print(f\"‚úÖ Created {len(training_df)} training sequences\")\n",
    "print(f\"üéØ Input features: {list(training_df.columns[:-1])}\")\n",
    "print(f\"üéØ Target: {training_df.columns[-1]}\")\n",
    "\n",
    "# Analyze the training data\n",
    "unique_current = training_df['current_h3_cell'].nunique()\n",
    "unique_targets = training_df['target_h3_cell'].nunique()\n",
    "\n",
    "print(f\"\\nüìä Training data analysis:\")\n",
    "print(f\"   - Unique current cells: {unique_current}\")\n",
    "print(f\"   - Unique target cells: {unique_targets}\")\n",
    "print(f\"   - Average speed: {training_df['current_speed'].mean():.1f} knots\")\n",
    "print(f\"   - Speed range: {training_df['current_speed'].min():.1f} - {training_df['current_speed'].max():.1f} knots\")\n",
    "\n",
    "display(training_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91ed9322",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize training patterns\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "\n",
    "# 1. Cell transition matrix (sample)\n",
    "transition_counts = training_df.groupby(['current_h3_cell', 'target_h3_cell']).size().reset_index(name='count')\n",
    "top_transitions = transition_counts.nlargest(10, 'count')\n",
    "\n",
    "axes[0,0].barh(range(len(top_transitions)), top_transitions['count'])\n",
    "axes[0,0].set_title('Top 10 H3 Cell Transitions')\n",
    "axes[0,0].set_xlabel('Frequency')\n",
    "axes[0,0].set_ylabel('Transition Rank')\n",
    "\n",
    "# 2. Speed vs heading relationship\n",
    "scatter = axes[0,1].scatter(training_df['current_heading'], training_df['current_speed'], \n",
    "                          alpha=0.5, s=10, c=training_df.index, cmap='viridis')\n",
    "axes[0,1].set_title('Speed vs Heading Pattern')\n",
    "axes[0,1].set_xlabel('Heading (degrees)')\n",
    "axes[0,1].set_ylabel('Speed (knots)')\n",
    "plt.colorbar(scatter, ax=axes[0,1], label='Time sequence')\n",
    "\n",
    "# 3. Geographic distribution of training points\n",
    "axes[1,0].scatter(training_df['lon'], training_df['lat'], alpha=0.5, s=10, color='navy')\n",
    "axes[1,0].set_title('Geographic Distribution of Training Data')\n",
    "axes[1,0].set_xlabel('Longitude')\n",
    "axes[1,0].set_ylabel('Latitude')\n",
    "axes[1,0].grid(True, alpha=0.3)\n",
    "\n",
    "# 4. Cell visit frequency\n",
    "cell_counts = training_df['current_h3_cell'].value_counts()\n",
    "axes[1,1].hist(cell_counts.values, bins=20, alpha=0.7, color='orange')\n",
    "axes[1,1].set_title('H3 Cell Visit Frequency')\n",
    "axes[1,1].set_xlabel('Number of Visits')\n",
    "axes[1,1].set_ylabel('Number of Cells')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"üìä Most visited cells:\")\n",
    "for i, (cell, count) in enumerate(cell_counts.head().items()):\n",
    "    print(f\"   {i+1}. {cell}: {count} visits\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49896585",
   "metadata": {},
   "source": [
    "## 5. Model Training & Evaluation ü§ñ\n",
    "\n",
    "Now let's train our Random Forest model and see how well it performs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dba8cba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load our trained model (if it exists) or train a new one\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import joblib\n",
    "\n",
    "# Check if we have a trained model\n",
    "model_path = '../data/models/final_models/simple_h3_predictor.pkl'\n",
    "encoder_path = '../data/models/final_models/h3_label_encoder.pkl'\n",
    "\n",
    "if os.path.exists(model_path) and os.path.exists(encoder_path):\n",
    "    print(\"üì¶ Loading existing trained model...\")\n",
    "    model = joblib.load(model_path)\n",
    "    h3_encoder = joblib.load(encoder_path)\n",
    "    print(\"‚úÖ Model loaded successfully!\")\n",
    "else:\n",
    "    print(\"ü§ñ Training new model...\")\n",
    "    \n",
    "    # Prepare data\n",
    "    h3_encoder = LabelEncoder()\n",
    "    all_h3_cells = list(set(training_df['current_h3_cell'].tolist() + training_df['target_h3_cell'].tolist()))\n",
    "    h3_encoder.fit(all_h3_cells)\n",
    "    \n",
    "    # Features (X) and target (y)\n",
    "    X = training_df[['current_speed', 'current_heading', 'lat', 'lon', 'time_in_current_cell']].copy()\n",
    "    X['current_h3_encoded'] = h3_encoder.transform(training_df['current_h3_cell'])\n",
    "    y = h3_encoder.transform(training_df['target_h3_cell'])\n",
    "    \n",
    "    # Train model\n",
    "    model = RandomForestClassifier(n_estimators=100, random_state=42, max_depth=15)\n",
    "    model.fit(X, y)\n",
    "    \n",
    "    # Save model\n",
    "    os.makedirs(os.path.dirname(model_path), exist_ok=True)\n",
    "    joblib.dump(model, model_path)\n",
    "    joblib.dump(h3_encoder, encoder_path)\n",
    "    print(\"üíæ Model saved!\")\n",
    "\n",
    "print(f\"üå≤ Model: RandomForest with {model.n_estimators} trees\")\n",
    "print(f\"üó∫Ô∏è Predicting among {len(h3_encoder.classes_)} possible H3 cells\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8099d720",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate model performance\n",
    "print(\"üìä Evaluating model performance...\")\n",
    "\n",
    "# Prepare test data\n",
    "X = training_df[['current_speed', 'current_heading', 'lat', 'lon', 'time_in_current_cell']].copy()\n",
    "X['current_h3_encoded'] = h3_encoder.transform(training_df['current_h3_cell'])\n",
    "y = h3_encoder.transform(training_df['target_h3_cell'])\n",
    "\n",
    "# Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Make predictions\n",
    "train_pred = model.predict(X_train)\n",
    "test_pred = model.predict(X_test)\n",
    "\n",
    "train_accuracy = accuracy_score(y_train, train_pred)\n",
    "test_accuracy = accuracy_score(y_test, test_pred)\n",
    "\n",
    "print(f\"üìà Training Accuracy: {train_accuracy:.1%}\")\n",
    "print(f\"üìà Test Accuracy: {test_accuracy:.1%}\")\n",
    "\n",
    "# Feature importance\n",
    "feature_names = X.columns\n",
    "importances = model.feature_importances_\n",
    "feature_importance = pd.DataFrame({\n",
    "    'feature': feature_names,\n",
    "    'importance': importances\n",
    "}).sort_values('importance', ascending=False)\n",
    "\n",
    "print(\"\\nüîç Feature Importance:\")\n",
    "for _, row in feature_importance.iterrows():\n",
    "    print(f\"   {row['feature']}: {row['importance']:.3f}\")\n",
    "\n",
    "# Plot feature importance\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.barh(feature_importance['feature'], feature_importance['importance'])\n",
    "plt.title('Feature Importance in H3 Cell Prediction')\n",
    "plt.xlabel('Importance')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31050f28",
   "metadata": {},
   "source": [
    "## 6. Prediction Visualization üîÆ\n",
    "\n",
    "Let's see our model's predictions in action on a map!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c885312",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions for a sequence\n",
    "print(\"üîÆ Making predictions for test sequence...\")\n",
    "\n",
    "# Take a subset for prediction visualization\n",
    "test_sequence = training_df.iloc[50:80].copy()  # 30 points for visualization\n",
    "\n",
    "predictions = []\n",
    "for _, row in test_sequence.iterrows():\n",
    "    # Prepare input\n",
    "    X_input = [[row['current_speed'], row['current_heading'], row['lat'], \n",
    "                row['lon'], row['time_in_current_cell'], \n",
    "                h3_encoder.transform([row['current_h3_cell']])[0]]]\n",
    "    \n",
    "    # Predict\n",
    "    pred_encoded = model.predict(X_input)[0]\n",
    "    pred_h3 = h3_encoder.inverse_transform([pred_encoded])[0]\n",
    "    \n",
    "    predictions.append({\n",
    "        'current_h3': row['current_h3_cell'],\n",
    "        'actual_next_h3': row['target_h3_cell'],\n",
    "        'predicted_next_h3': pred_h3,\n",
    "        'correct': pred_h3 == row['target_h3_cell'],\n",
    "        'lat': row['lat'],\n",
    "        'lon': row['lon'],\n",
    "        'speed': row['current_speed'],\n",
    "        'heading': row['current_heading']\n",
    "    })\n",
    "\n",
    "pred_df = pd.DataFrame(predictions)\n",
    "accuracy_subset = pred_df['correct'].mean()\n",
    "\n",
    "print(f\"‚úÖ Made predictions for {len(pred_df)} points\")\n",
    "print(f\"üìä Accuracy on this subset: {accuracy_subset:.1%}\")\n",
    "print(f\"üéØ Correct predictions: {pred_df['correct'].sum()}/{len(pred_df)}\")\n",
    "\n",
    "display(pred_df[['current_h3', 'actual_next_h3', 'predicted_next_h3', 'correct', 'speed']].head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c18ad505",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create prediction visualization map\n",
    "def create_prediction_map(pred_df):\n",
    "    \"\"\"Create map showing predictions vs actual movements\"\"\"\n",
    "    \n",
    "    center_lat = pred_df['lat'].mean()\n",
    "    center_lon = pred_df['lon'].mean()\n",
    "    \n",
    "    m = folium.Map(\n",
    "        location=[center_lat, center_lon],\n",
    "        zoom_start=12,\n",
    "        tiles='OpenStreetMap'\n",
    "    )\n",
    "    \n",
    "    # Add prediction points\n",
    "    for i, row in pred_df.iterrows():\n",
    "        # Color based on correctness\n",
    "        color = 'green' if row['correct'] else 'red'\n",
    "        icon = 'ok' if row['correct'] else 'remove'\n",
    "        \n",
    "        # Current position marker\n",
    "        folium.Marker(\n",
    "            [row['lat'], row['lon']],\n",
    "            popup=f\"\"\"Point {i+1}<br>\n",
    "                     Speed: {row['speed']:.1f} knots<br>\n",
    "                     Current: {row['current_h3'][-6:]}<br>\n",
    "                     Actual: {row['actual_next_h3'][-6:]}<br>\n",
    "                     Predicted: {row['predicted_next_h3'][-6:]}<br>\n",
    "                     Correct: {row['correct']}\"\"\",\n",
    "            icon=folium.Icon(color=color, icon=icon)\n",
    "        ).add_to(m)\n",
    "        \n",
    "        # Add actual H3 cell boundary\n",
    "        actual_boundary = h3.h3_to_geo_boundary(row['actual_next_h3'], geo_json=True)\n",
    "        folium.Polygon(\n",
    "            actual_boundary,\n",
    "            color='blue',\n",
    "            weight=2,\n",
    "            fillColor='blue',\n",
    "            fillOpacity=0.2,\n",
    "            popup=f'Actual: {row[\"actual_next_h3\"][-6:]}'\n",
    "        ).add_to(m)\n",
    "        \n",
    "        # Add predicted H3 cell boundary (if different)\n",
    "        if row['predicted_next_h3'] != row['actual_next_h3']:\n",
    "            pred_boundary = h3.h3_to_geo_boundary(row['predicted_next_h3'], geo_json=True)\n",
    "            folium.Polygon(\n",
    "                pred_boundary,\n",
    "                color='red',\n",
    "                weight=2,\n",
    "                fillColor='red',\n",
    "                fillOpacity=0.2,\n",
    "                popup=f'Predicted: {row[\"predicted_next_h3\"][-6:]}'\n",
    "            ).add_to(m)\n",
    "    \n",
    "    # Add legend\n",
    "    legend_html = '''\n",
    "    <div style=\"position: fixed; \n",
    "                bottom: 50px; left: 50px; width: 200px; height: 90px; \n",
    "                background-color: white; border:2px solid grey; z-index:9999; \n",
    "                font-size:14px; padding: 10px\">\n",
    "    <b>Prediction Legend</b><br>\n",
    "    üü¢ Correct Prediction<br>\n",
    "    üî¥ Incorrect Prediction<br>\n",
    "    üü¶ Actual Next Cell<br>\n",
    "    üü• Predicted Next Cell\n",
    "    </div>\n",
    "    '''\n",
    "    m.get_root().html.add_child(folium.Element(legend_html))\n",
    "    \n",
    "    return m\n",
    "\n",
    "print(\"üó∫Ô∏è Creating prediction visualization map...\")\n",
    "prediction_map = create_prediction_map(pred_df)\n",
    "\n",
    "# Save map\n",
    "pred_map_path = '../visualizations/vessel_predictions_map.html'\n",
    "prediction_map.save(pred_map_path)\n",
    "print(f\"üíæ Prediction map saved to: {pred_map_path}\")\n",
    "\n",
    "# Display map\n",
    "prediction_map"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fcfbeaf",
   "metadata": {},
   "source": [
    "## 7. Results Summary üìä\n",
    "\n",
    "Let's summarize what we've accomplished and learned from this analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d40db26c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate comprehensive summary\n",
    "print(\"=\" * 60)\n",
    "print(\"üö¢ VESSEL TRAJECTORY PREDICTION - RESULTS SUMMARY\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "print(f\"\\nüìä DATA PIPELINE:\")\n",
    "print(f\"   Raw AIS Records: {len(df):,}\")\n",
    "print(f\"   Vessels Available: {df['imo'].nunique()}\")\n",
    "print(f\"   Test Vessel: {test_vessel_imo}\")\n",
    "print(f\"   Analysis Points: {len(test_vessel_data)}\")\n",
    "\n",
    "print(f\"\\nüó∫Ô∏è SPATIAL FRAMEWORK:\")\n",
    "print(f\"   H3 Resolution: 5\")\n",
    "print(f\"   Cell Edge Length: ~{h3.edge_length(5, unit='km'):.1f} km\")\n",
    "print(f\"   Unique Cells Visited: {len(unique_cells)}\")\n",
    "print(f\"   H3 Sequence Length: {len(h3_sequence)}\")\n",
    "\n",
    "print(f\"\\nüîß FEATURE ENGINEERING:\")\n",
    "print(f\"   Total Features: {len(features_df.columns)}\")\n",
    "print(f\"   Feature Categories: Core state, Historical patterns, Movement characteristics, Context\")\n",
    "print(f\"   Data Completeness: {(features_df.count().sum() / (len(features_df) * len(features_df.columns)) * 100):.1f}%\")\n",
    "\n",
    "print(f\"\\nü§ñ MACHINE LEARNING:\")\n",
    "print(f\"   Model: Random Forest\")\n",
    "print(f\"   Training Samples: {len(training_df)}\")\n",
    "print(f\"   Prediction Classes: {len(h3_encoder.classes_)} H3 cells\")\n",
    "print(f\"   Test Accuracy: {test_accuracy:.1%}\")\n",
    "\n",
    "print(f\"\\nüéØ KEY INSIGHTS:\")\n",
    "print(f\"   Most Important Features: {', '.join(feature_importance.head(3)['feature'].values)}\")\n",
    "print(f\"   Geographic Factors: Location (lat/lon) are highly predictive\")\n",
    "print(f\"   Movement Factors: Current H3 cell and speed matter significantly\")\n",
    "print(f\"   Prediction Challenge: {len(h3_encoder.classes_)} possible destinations make this complex\")\n",
    "\n",
    "print(f\"\\nüöÄ NEXT STEPS FOR IMPROVEMENT:\")\n",
    "print(f\"   1. Add more vessels to training data\")\n",
    "print(f\"   2. Use sequential models (LSTM) instead of Random Forest\")\n",
    "print(f\"   3. Include more of the 65 available features\")\n",
    "print(f\"   4. Implement temporal sequence prediction\")\n",
    "print(f\"   5. Add external factors (weather, traffic)\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"‚úÖ ANALYSIS COMPLETE - WORKING ML PIPELINE ESTABLISHED!\")\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08739c7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save analysis results\n",
    "results_summary = {\n",
    "    'dataset_size': len(df),\n",
    "    'test_vessel': str(test_vessel_imo),\n",
    "    'h3_resolution': 5,\n",
    "    'unique_cells': len(unique_cells),\n",
    "    'feature_count': len(features_df.columns),\n",
    "    'training_samples': len(training_df),\n",
    "    'test_accuracy': float(test_accuracy),\n",
    "    'model_type': 'RandomForest',\n",
    "    'feature_importance': feature_importance.to_dict('records')\n",
    "}\n",
    "\n",
    "import json\n",
    "results_path = '../data/processed/analysis_results.json'\n",
    "with open(results_path, 'w') as f:\n",
    "    json.dump(results_summary, f, indent=2)\n",
    "\n",
    "print(f\"üíæ Analysis results saved to: {results_path}\")\n",
    "print(\"üéâ Notebook analysis complete!\")\n",
    "print(\"\\nüìÅ Generated files:\")\n",
    "print(f\"   - Vessel track map: ../visualizations/vessel_h3_training_data.html\")\n",
    "print(f\"   - Prediction map: ../visualizations/vessel_predictions_map.html\")\n",
    "print(f\"   - Analysis results: {results_path}\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
